# OpenClaw Expert â€” OpenClaw Skill

**Lokaal RAG-systeem (Retrieval-Augmented Generation) voor volledige OpenClaw documentatie.**

Semantische zoeken + lokale LLM = snelle, nauwkeurige antwoorden op vragen over OpenClaw. Volledig privacy-preserved, geen cloud afhankelijkheden.

---

## ğŸ¯ Wat doet OpenClaw Expert?

OpenClaw Expert is een **Retrieval-Augmented Generation (RAG)** systeem dat:

- **Alle OpenClaw docs indexeert** â€” 99 markdown files van https://docs.openclaw.ai/
- **Semantische zoeking** â€” Vindt relevante docs via vector embeddings
- **Lokale LLM antwoorden** â€” Genereert antwoorden via Mistral (Ollama, geen cloud)
- **Geciteerde bronnen** â€” Elke antwoord bevat links naar bron-docs
- **Volledig privÃ©** â€” Alles lokaal, geen external API calls

### ğŸ”„ Workflow

```
User Question
    â†“
nomic-embed-text (local)
    â†“
ChromaDB Vector Search
    â†“
Top 5 matching docs
    â†“
Mistral Small 24B (local)
    â†“
Generated Answer + Source URLs
```

---

## ğŸ“¦ Afhankelijkheden

### Systeemvereisten
- **Python:** 3.8+
- **Ollama:** https://ollama.ai (nodig voor LLM + embeddings)

### Ollama Models (automatisch gedownload)
```
nomic-embed-text:latest       # Embeddings (768-dim vectors)
mistral-small3.1:24b          # Language model (7B parameters)
```

### Python Dependencies

```
chromadb>=0.3.21              # Vector database
ollama>=0.1.0                 # Ollama Python client
beautifulsoup4>=4.11.0        # HTML parsing (voor docs scraping)
requests>=2.28.0              # HTTP requests
markdownify>=0.11.0           # Convert HTML to Markdown
python-dotenv>=0.20.0         # .env loading
```

### Hardware Requirements
- **RAM:** 8GB minimum (Mistral 24B = ~16GB)
- **Disk:** 20GB (embeddings + models cache)
- **CPU:** Modern processor (Intel i7+, Apple Silicon, AMD Ryzen+)

---

## âš¡ Quickstart

### 1. Installatie

```bash
# Clone de repository
git clone https://github.com/bonzen-nl/oc-openclaw-expert
cd oc-openclaw-expert

# Maak virtual environment
python3 -m venv .venv
source .venv/bin/activate

# Installeer dependencies
pip install -r requirements.txt
```

### 2. Ollama Setup

```bash
# Download Ollama (Ã©Ã©n keer)
brew install ollama

# Start Ollama daemon
ollama serve

# In aparte terminal, pull models
ollama pull nomic-embed-text
ollama pull mistral-small3.1:24b
```

### 3. Configuratie

```bash
# Kopieer template
cp .env.example .env

# Instellingen (optioneel):
# OLLAMA_BASE_URL=http://127.0.0.1:11434
# CHROMADB_PATH=./index_data
```

### 4. Database Initialiseren

```bash
# Download + index OpenClaw docs (Ã©Ã©n keer, ~5 min)
python3 scripts/initialize_rag.py

# Output: âœ… 99 docs indexed, 99 vectors created
```

### 5. Test Query

```bash
python3 scripts/query_expert.py "Hoe configureer ik een agent?"

# Output:
# [Antwoord in Nederlands]
# 
# ğŸ“š Bronnen:
# - https://docs.openclaw.ai/agents/configuration
# - https://docs.openclaw.ai/agents/overview
# ...
```

---

## ğŸš€ Gebruik

### Via CLI

```bash
# Query directly
python3 scripts/query_expert.py "Wat zijn de vereisten voor OpenClaw?"

# Output formatted (JSON)
python3 scripts/query_expert.py \
  "Hoe debug ik een skill?" \
  --format json

# Advanced: Custom model parameters
python3 scripts/query_expert.py \
  "Verklaar het RAG concept" \
  --temperature 0.5 \
  --top-k 10
```

### Via Python API

```python
from lib.expert import OpenClawExpert

expert = OpenClawExpert()

# Simple query
answer = expert.query("Wat is een skill?")
print(answer["text"])
print(answer["sources"])  # URLs

# Advanced
result = expert.query_advanced(
    question="OAuth2 implementatie",
    top_k=5,
    temperature=0.3
)
```

### Integratie met Software-Architect

```python
# Architect kan expert raadplegen
architect = SoftwareArchitectExpert()
context = architect.consult_expert(
    question="Wat zijn de best practices voor error handling?"
)
# â†’ Context wordt toegevoegd aan complex task routing
```

---

## ğŸ—ï¸ Projectstructuur

```
oc-openclaw-expert/
â”œâ”€â”€ SKILL.md                          # Skill documentatie
â”œâ”€â”€ README.md                         # Dit bestand
â”œâ”€â”€ requirements.txt                  # Python dependencies
â”œâ”€â”€ .env.example                      # Configuration template
â”œâ”€â”€ .gitignore                        # Git security
â”œâ”€â”€ LICENSE                           # MIT
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ ollama_config.json            # Model parameters
â”‚   â””â”€â”€ openclaw_expert_config.json   # Expert settings
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ initialize_rag.py             # Download + index docs
â”‚   â”œâ”€â”€ query_expert.py               # CLI query interface
â”‚   â””â”€â”€ scrape_docs.py                # Fetch OpenClaw docs
â”œâ”€â”€ lib/
â”‚   â””â”€â”€ expert.py                     # Core RAG engine
â”œâ”€â”€ index_data/
â”‚   â””â”€â”€ openclaw_chroma_local.json    # Vector database (generated)
â””â”€â”€ .venv/                            # Virtual environment
```

---

## ğŸ“š Volledige Documentatie

- **[SKILL.md](./SKILL.md)** â€” Skill-definitie en workflows
- **[config/](./config/)** â€” Configuration options
- **[scripts/](./scripts/)** â€” Command-line tools

---

## ğŸ” RAG System Details

### Vector Database (ChromaDB)

```json
{
  "99 documents": [
    {
      "id": "doc_001",
      "source_url": "https://docs.openclaw.ai/agents/overview",
      "embedding": [0.123, 0.456, ...],  // 768-dimensional vector
      "metadata": {"title": "...", "category": "agents"}
    }
  ]
}
```

### Query Process

1. **Embed Query** â€” User's vraag â†’ nomic-embed-text â†’ vector
2. **Search** â€” ChromaDB finds top-5 most similar docs
3. **Augment** â€” Combine docs + query for context
4. **Generate** â€” Mistral produces answer
5. **Cite** â€” Attach source URLs

### Performance

- **Query latency:** ~3-5 seconds (local, no network)
- **Embedding quality:** High (nomic-embed-text trained on OpenClaw-like docs)
- **Token efficiency:** ~200-500 tokens per response
- **Throughput:** ~10-15 queries/minute (single GPU/CPU)

---

## ğŸ” Veiligheid & Privacy

### Local Processing
âœ… Alle verwerking lokaal (geen cloud API calls)
âœ… Documenten niet geupload
âœ… Queries niet gelogd naar externe servers
âœ… Volledig privacy-preserved

### Data Files
```bash
.env                           # NEVER commit (contains secrets)
index_data/                    # Safe (public OpenClaw docs)
.venv/                         # Never commit
```

---

## ğŸ§ª Testing & Maintenance

### Rebuild Index

```bash
# If docs updated on docs.openclaw.ai
python3 scripts/initialize_rag.py --force

# Check index integrity
python3 scripts/query_expert.py --check-db
```

### Performance Check

```bash
# Benchmark query speed
python3 -c "
from lib.expert import OpenClawExpert
import time

expert = OpenClawExpert()
start = time.time()
result = expert.query('Test query')
print(f'Latency: {time.time() - start:.2f}s')
"
```

---

## ğŸ› Troubleshooting

### Ollama Not Running
```bash
# Start daemon
ollama serve

# Or in background
nohup ollama serve > /tmp/ollama.log 2>&1 &
```

### Models Not Downloaded
```bash
ollama pull nomic-embed-text
ollama pull mistral-small3.1:24b

# Verify
ollama list
```

### "No documents found"
- Rebuild index: `python3 scripts/initialize_rag.py --force`
- Check ChromaDB: `ls -la index_data/openclaw_chroma_local.json`

### Slow Responses
- Increase RAM available to Ollama
- Check: `ollama ps` (running models)
- Reduce `top_k` parameter (fewer docs to search)

---

## ğŸ”— Sub-Projecten & Integraties

OpenClaw Expert is onderdeel van het **OpenClaw Skills Ecosystem**:

### Master Hub
- **[oc-overzicht](https://github.com/bonzen-nl/oc-overzicht)** â€” Centrale index

### Gerelateerde Skills
- **[oc-software-architect](https://github.com/bonzen-nl/oc-software-architect)** â€” Roept expert aan voor context
- **[oc-github-manager](https://github.com/bonzen-nl/oc-github-manager)** â€” Integreert expert in issue-beschrijvingen
- **[oc-server-status](https://github.com/bonzen-nl/oc-server-status)** â€” Health monitoring
- **[oc-ram-guardian](https://github.com/bonzen-nl/oc-ram-guardian)** â€” Memory optimization

### Integration Points

**Software-Architect consults Expert:**
```python
# Architect checks expert voor context
expert_answer = expert.query("Wat zijn de OpenClaw skill best practices?")
# â†’ Used to inform complex decision-making
```

**GitHub Manager uses Expert:**
```python
# Auto-generate issue descriptions based on expert knowledge
issue_template = expert.query("Template voor feature request")
```

---

## ğŸ“Š Index Statistics

- **Total Documents:** 99
- **Total Vectors:** 99 (768-dim each)
- **Index Size:** ~2.5 MB
- **Vector Dimension:** 768 (nomic-embed-text)
- **Last Updated:** [Auto-synced weekly]

---

## ğŸš€ Deployment

### Standalone
```bash
# Run Expert service (listens on 8000)
python3 scripts/serve_expert.py
curl http://localhost:8000/query?q=What+is+a+skill?
```

### With OpenClaw
```bash
# Expert auto-available to software-architect
# No extra setup needed
```

---

## ğŸ“ Licentie

MIT Â© 2026 Bonzen

---

## ğŸ“¬ Ondersteuning

- **Issues:** [oc-openclaw-expert/issues](https://github.com/bonzen-nl/oc-openclaw-expert/issues)
- **Architecture Question:** Zie [oc-software-architect](https://github.com/bonzen-nl/oc-software-architect)

---

**Onderdeel van:** [OpenClaw Skills Suite](https://github.com/bonzen-nl/oc-overzicht)
